{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a77807f92f26ee",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f32d0ebbbd7602f6",
   "metadata": {},
   "source": [
    "## 1. Подготовка к работе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d92f41d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24e690f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nltk\n",
    "# !pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbc121e30a2defb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T00:02:38.853075Z",
     "start_time": "2024-12-08T00:02:38.850042Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from transformers import Trainer, TrainingArguments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0f60002656a80f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T01:32:38.798687Z",
     "start_time": "2024-12-07T01:32:38.627279Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pront\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646653922d65fb36",
   "metadata": {},
   "source": [
    "##  2. Загрузка и предварительная обработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbadb88669734d30",
   "metadata": {},
   "source": [
    "### 2.1. Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2520816349bcb1d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T23:24:00.598099Z",
     "start_time": "2024-12-07T23:24:00.447511Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>name_ru</th>\n",
       "      <th>rating</th>\n",
       "      <th>rubrics</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Екатеринбург, ул. Московская / ул. Волгоградск...</td>\n",
       "      <td>Московский квартал</td>\n",
       "      <td>3</td>\n",
       "      <td>Жилой комплекс</td>\n",
       "      <td>Московский квартал 2. Шумно : летом по ночам д...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Московская область, Электросталь, проспект Лен...</td>\n",
       "      <td>Продукты Ермолино</td>\n",
       "      <td>5</td>\n",
       "      <td>Магазин продуктов;Продукты глубокой заморозки;...</td>\n",
       "      <td>Замечательная сеть магазинов в общем, хороший ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Краснодар, Прикубанский внутригородской округ,...</td>\n",
       "      <td>LimeFit</td>\n",
       "      <td>1</td>\n",
       "      <td>Фитнес-клуб</td>\n",
       "      <td>Не знаю смутят ли кого-то данные правила, но я...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Санкт-Петербург, проспект Энгельса, 111, корп. 1</td>\n",
       "      <td>Snow-Express</td>\n",
       "      <td>4</td>\n",
       "      <td>Пункт проката;Прокат велосипедов;Сапсёрфинг</td>\n",
       "      <td>Хорошие условия аренды.  Дружелюбный персонал....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Тверь, Волоколамский проспект, 39</td>\n",
       "      <td>Студия Beauty Brow</td>\n",
       "      <td>5</td>\n",
       "      <td>Салон красоты;Визажисты, стилисты;Салон бровей...</td>\n",
       "      <td>Топ мастер Ангелина топ во всех смыслах ) Немн...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             address             name_ru  \\\n",
       "0  Екатеринбург, ул. Московская / ул. Волгоградск...  Московский квартал   \n",
       "1  Московская область, Электросталь, проспект Лен...   Продукты Ермолино   \n",
       "2  Краснодар, Прикубанский внутригородской округ,...             LimeFit   \n",
       "3   Санкт-Петербург, проспект Энгельса, 111, корп. 1        Snow-Express   \n",
       "4                  Тверь, Волоколамский проспект, 39  Студия Beauty Brow   \n",
       "\n",
       "   rating                                            rubrics  \\\n",
       "0       3                                     Жилой комплекс   \n",
       "1       5  Магазин продуктов;Продукты глубокой заморозки;...   \n",
       "2       1                                        Фитнес-клуб   \n",
       "3       4        Пункт проката;Прокат велосипедов;Сапсёрфинг   \n",
       "4       5  Салон красоты;Визажисты, стилисты;Салон бровей...   \n",
       "\n",
       "                                                text  \n",
       "0  Московский квартал 2. Шумно : летом по ночам д...  \n",
       "1  Замечательная сеть магазинов в общем, хороший ...  \n",
       "2  Не знаю смутят ли кого-то данные правила, но я...  \n",
       "3  Хорошие условия аренды.  Дружелюбный персонал....  \n",
       "4  Топ мастер Ангелина топ во всех смыслах ) Немн...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/work_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfdcb228ac9b2293",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T01:32:38.990608Z",
     "start_time": "2024-12-07T01:32:38.984419Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 498918 entries, 0 to 498917\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count   Dtype \n",
      "---  ------   --------------   ----- \n",
      " 0   address  498918 non-null  object\n",
      " 1   name_ru  498918 non-null  object\n",
      " 2   rating   498918 non-null  int64 \n",
      " 3   rubrics  498918 non-null  object\n",
      " 4   text     498918 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 19.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fa7c11e7cf017a",
   "metadata": {},
   "source": [
    "### 2.2. Фильтрация и очистка данных\n",
    "\n",
    "Возьмем данные, которые не содержат короткие отзывы (меньше 10 символов) и не содержат пропусков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f0ae3baec3a88e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T13:04:36.551653Z",
     "start_time": "2024-12-08T13:04:36.223522Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 498918 entries, 0 to 498917\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   address  498918 non-null  object \n",
      " 1   name_ru  498918 non-null  object \n",
      " 2   rating   498918 non-null  float64\n",
      " 3   rubrics  498918 non-null  object \n",
      " 4   text     498918 non-null  object \n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 19.0+ MB\n"
     ]
    }
   ],
   "source": [
    "def clean_review_text(text: str) -> str:\n",
    "    text = text.lower()  # Приводим к нижнему регистру\n",
    "    text = re.sub(r\"<[^>]+>\", \"\", text)  # Удаляем HTML-теги\n",
    "    text = re.sub(r\"[^\\w\\s,.!?()]+\", \"\", text)  # Удаляем спецсимволы, кроме пунктуации и скобок\n",
    "    text = re.sub(r\"\\)\\)+\", \" \", text)  # Заменяем смайлики вида \"))\" на пробел\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()  # Убираем лишние пробелы\n",
    "    text = re.sub(r\"[\\n\\r]+\", \" \", text)  # Заменяем переносы строк на пробелы\n",
    "    return text\n",
    "\n",
    "\n",
    "def clean_rubrics(rubrics_: str) -> str:\n",
    "    return rubrics_.lower().strip()\n",
    "\n",
    "\n",
    "def clean_name_ru(name_ru: str) -> str:\n",
    "    return name_ru.lower().strip()\n",
    "\n",
    "\n",
    "def clean_address(address: str) -> str:\n",
    "    address = address.strip()\n",
    "    return re.sub(r\"\\s+\", \" \", address)\n",
    "\n",
    "\n",
    "df['text'] = df['text'].apply(clean_review_text)\n",
    "df['rubrics'] = df['rubrics'].apply(clean_rubrics)\n",
    "df['name_ru'] = df['name_ru'].apply(clean_name_ru)\n",
    "df['address'] = df['address'].apply(clean_address)\n",
    "\n",
    "# Преобразование рейтинга в числовой формат\n",
    "df['rating'] = df['rating'].astype(float)\n",
    "\n",
    "# Удаление строк с пропущенными значениями\n",
    "df.dropna(subset=['address', 'name_ru', 'rubrics', 'rating', 'text'], inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f46266642c1e6375",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T12:58:20.628556Z",
     "start_time": "2024-12-08T12:58:20.624208Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>name_ru</th>\n",
       "      <th>rating</th>\n",
       "      <th>rubrics</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Екатеринбург, ул. Московская / ул. Волгоградск...</td>\n",
       "      <td>московский квартал</td>\n",
       "      <td>3.0</td>\n",
       "      <td>жилой комплекс</td>\n",
       "      <td>московский квартал 2. шумно летом по ночам дик...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Московская область, Электросталь, проспект Лен...</td>\n",
       "      <td>продукты ермолино</td>\n",
       "      <td>5.0</td>\n",
       "      <td>магазин продуктов;продукты глубокой заморозки;...</td>\n",
       "      <td>замечательная сеть магазинов в общем, хороший ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Краснодар, Прикубанский внутригородской округ,...</td>\n",
       "      <td>limefit</td>\n",
       "      <td>1.0</td>\n",
       "      <td>фитнес-клуб</td>\n",
       "      <td>не знаю смутят ли когото данные правила, но я ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Санкт-Петербург, проспект Энгельса, 111, корп. 1</td>\n",
       "      <td>snow-express</td>\n",
       "      <td>4.0</td>\n",
       "      <td>пункт проката;прокат велосипедов;сапсёрфинг</td>\n",
       "      <td>хорошие условия аренды. дружелюбный персонал. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Тверь, Волоколамский проспект, 39</td>\n",
       "      <td>студия beauty brow</td>\n",
       "      <td>5.0</td>\n",
       "      <td>салон красоты;визажисты, стилисты;салон бровей...</td>\n",
       "      <td>топ мастер ангелина топ во всех смыслах ) немн...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             address             name_ru  \\\n",
       "0  Екатеринбург, ул. Московская / ул. Волгоградск...  московский квартал   \n",
       "1  Московская область, Электросталь, проспект Лен...   продукты ермолино   \n",
       "2  Краснодар, Прикубанский внутригородской округ,...             limefit   \n",
       "3   Санкт-Петербург, проспект Энгельса, 111, корп. 1        snow-express   \n",
       "4                  Тверь, Волоколамский проспект, 39  студия beauty brow   \n",
       "\n",
       "   rating                                            rubrics  \\\n",
       "0     3.0                                     жилой комплекс   \n",
       "1     5.0  магазин продуктов;продукты глубокой заморозки;...   \n",
       "2     1.0                                        фитнес-клуб   \n",
       "3     4.0        пункт проката;прокат велосипедов;сапсёрфинг   \n",
       "4     5.0  салон красоты;визажисты, стилисты;салон бровей...   \n",
       "\n",
       "                                                text  \n",
       "0  московский квартал 2. шумно летом по ночам дик...  \n",
       "1  замечательная сеть магазинов в общем, хороший ...  \n",
       "2  не знаю смутят ли когото данные правила, но я ...  \n",
       "3  хорошие условия аренды. дружелюбный персонал. ...  \n",
       "4  топ мастер ангелина топ во всех смыслах ) немн...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752320017b41219d",
   "metadata": {},
   "source": [
    "### 2.3. Создание входного запроса для модели\n",
    "\n",
    "Мы будем формировать входной текст для модели, который будет содержать категорию, рейтинг и ключевые слова. В качестве ключевых слов будем использовать рубрики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aeb36a2bab9d546b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T13:15:37.849283Z",
     "start_time": "2024-12-08T13:15:37.772908Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>name_ru</th>\n",
       "      <th>rating</th>\n",
       "      <th>rubrics</th>\n",
       "      <th>text</th>\n",
       "      <th>input_text</th>\n",
       "      <th>target_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Екатеринбург, ул. Московская / ул. Волгоградск...</td>\n",
       "      <td>московский квартал</td>\n",
       "      <td>3.0</td>\n",
       "      <td>жилой комплекс</td>\n",
       "      <td>московский квартал 2. шумно летом по ночам дик...</td>\n",
       "      <td>\\nКатегория: жилой комплекс\\nРейтинг: 3.0\\nКлю...</td>\n",
       "      <td>московский квартал 2. шумно летом по ночам дик...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Московская область, Электросталь, проспект Лен...</td>\n",
       "      <td>продукты ермолино</td>\n",
       "      <td>5.0</td>\n",
       "      <td>магазин продуктов;продукты глубокой заморозки;...</td>\n",
       "      <td>замечательная сеть магазинов в общем, хороший ...</td>\n",
       "      <td>\\nКатегория: магазин продуктов, продукты глубо...</td>\n",
       "      <td>замечательная сеть магазинов в общем, хороший ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Краснодар, Прикубанский внутригородской округ,...</td>\n",
       "      <td>limefit</td>\n",
       "      <td>1.0</td>\n",
       "      <td>фитнес-клуб</td>\n",
       "      <td>не знаю смутят ли когото данные правила, но я ...</td>\n",
       "      <td>\\nКатегория: фитнес-клуб\\nРейтинг: 1.0\\nКлючев...</td>\n",
       "      <td>не знаю смутят ли когото данные правила, но я ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Санкт-Петербург, проспект Энгельса, 111, корп. 1</td>\n",
       "      <td>snow-express</td>\n",
       "      <td>4.0</td>\n",
       "      <td>пункт проката;прокат велосипедов;сапсёрфинг</td>\n",
       "      <td>хорошие условия аренды. дружелюбный персонал. ...</td>\n",
       "      <td>\\nКатегория: пункт проката, прокат велосипедов...</td>\n",
       "      <td>хорошие условия аренды. дружелюбный персонал. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Тверь, Волоколамский проспект, 39</td>\n",
       "      <td>студия beauty brow</td>\n",
       "      <td>5.0</td>\n",
       "      <td>салон красоты;визажисты, стилисты;салон бровей...</td>\n",
       "      <td>топ мастер ангелина топ во всех смыслах ) немн...</td>\n",
       "      <td>\\nКатегория: салон красоты, визажисты, стилист...</td>\n",
       "      <td>топ мастер ангелина топ во всех смыслах ) немн...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             address             name_ru  \\\n",
       "0  Екатеринбург, ул. Московская / ул. Волгоградск...  московский квартал   \n",
       "1  Московская область, Электросталь, проспект Лен...   продукты ермолино   \n",
       "2  Краснодар, Прикубанский внутригородской округ,...             limefit   \n",
       "3   Санкт-Петербург, проспект Энгельса, 111, корп. 1        snow-express   \n",
       "4                  Тверь, Волоколамский проспект, 39  студия beauty brow   \n",
       "\n",
       "   rating                                            rubrics  \\\n",
       "0     3.0                                     жилой комплекс   \n",
       "1     5.0  магазин продуктов;продукты глубокой заморозки;...   \n",
       "2     1.0                                        фитнес-клуб   \n",
       "3     4.0        пункт проката;прокат велосипедов;сапсёрфинг   \n",
       "4     5.0  салон красоты;визажисты, стилисты;салон бровей...   \n",
       "\n",
       "                                                text  \\\n",
       "0  московский квартал 2. шумно летом по ночам дик...   \n",
       "1  замечательная сеть магазинов в общем, хороший ...   \n",
       "2  не знаю смутят ли когото данные правила, но я ...   \n",
       "3  хорошие условия аренды. дружелюбный персонал. ...   \n",
       "4  топ мастер ангелина топ во всех смыслах ) немн...   \n",
       "\n",
       "                                          input_text  \\\n",
       "0  \\nКатегория: жилой комплекс\\nРейтинг: 3.0\\nКлю...   \n",
       "1  \\nКатегория: магазин продуктов, продукты глубо...   \n",
       "2  \\nКатегория: фитнес-клуб\\nРейтинг: 1.0\\nКлючев...   \n",
       "3  \\nКатегория: пункт проката, прокат велосипедов...   \n",
       "4  \\nКатегория: салон красоты, визажисты, стилист...   \n",
       "\n",
       "                                         target_text  \n",
       "0  московский квартал 2. шумно летом по ночам дик...  \n",
       "1  замечательная сеть магазинов в общем, хороший ...  \n",
       "2  не знаю смутят ли когото данные правила, но я ...  \n",
       "3  хорошие условия аренды. дружелюбный персонал. ...  \n",
       "4  топ мастер ангелина топ во всех смыслах ) немн...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROMT_PATTERN = \"\"\"\n",
    "Категория: {categories}\n",
    "Рейтинг: {rating}\n",
    "Ключевые слова: {keywords}\n",
    "Отзыв:\n",
    "\"\"\"\n",
    "\n",
    "def preprocess_row(row):\n",
    "    categories = row['rubrics'].split(';')  # Предполагается, что рубрики разделены запятыми\n",
    "    categories = [cat.strip() for cat in categories]\n",
    "    categories_str = ', '.join(categories)\n",
    "    keywords = \" \".join(categories)  # Можно дополнительно извлечь ключевые слова из текста\n",
    "    formatted_text = PROMT_PATTERN.format(categories=categories_str, rating=row['rating'], keywords=keywords)\n",
    "    return formatted_text\n",
    "\n",
    "df['input_text'] = df.apply(preprocess_row, axis=1)\n",
    "df['target_text'] = df['text'].str.strip()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde47416127307c",
   "metadata": {},
   "source": [
    "### 2.5. Разделение данных на обучающую и тестовую выборки\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c120a77790cfcb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T13:17:28.601405Z",
     "start_time": "2024-12-08T13:17:28.592738Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер обучающей выборки: 449026\n",
      "Размер валидационной выборки: 49892\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df = train_test_split(df, test_size=0.1, random_state=42)\n",
    "\n",
    "print(f\"Размер обучающей выборки: {len(train_df)}\")\n",
    "print(f\"Размер валидационной выборки: {len(val_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ffb9a1def448d3",
   "metadata": {},
   "source": [
    "## 3. Создание датасета и загрузчика данных\n",
    "\n",
    "Используем PyTorch для создания пользовательского датасета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "532ee884a9efbec5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T15:18:27.870958Z",
     "start_time": "2024-12-08T15:18:27.435543Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "class ReviewsDataset(Dataset):\n",
    "    def __init__(self, inputs, targets, tokenizer, max_length=512):\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_enc = self.tokenizer.encode_plus(\n",
    "            self.inputs[idx],\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        target_enc = self.tokenizer.encode_plus(\n",
    "            self.targets[idx],\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        labels = target_enc['input_ids']\n",
    "        labels[labels == self.tokenizer.pad_token_id] = -100  # Игнорирование паддинга при расчете лосса\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_enc['input_ids'].squeeze(),\n",
    "            'attention_mask': input_enc['attention_mask'].squeeze(),\n",
    "            'labels': labels.squeeze()\n",
    "        }\n",
    "\n",
    "# Выбор модели и токенизатора\n",
    "model_name = 'sberbank-ai/rugpt3small_based_on_gpt2'\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Добавление специальных токенов, если необходимо\n",
    "# tokenizer.add_special_tokens({'pad_token': '[PAD]'})  # Например, добавление PAD токена\n",
    "\n",
    "# Создание датасетов\n",
    "train_dataset = ReviewsDataset(\n",
    "    inputs=train_df['input_text'].tolist(),\n",
    "    targets=train_df['target_text'].tolist(),\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "val_dataset = ReviewsDataset(\n",
    "    inputs=val_df['input_text'].tolist(),\n",
    "    targets=val_df['target_text'].tolist(),\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Создание загрузчиков данных\n",
    "batch_size = 8\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ade93c17bfd541",
   "metadata": {},
   "source": [
    "## 4. Выбор и настройка модели\n",
    "\n",
    "Мы будем использовать предобученную модель ruGPT-3 Small, предоставленную SberAI. Вы можете выбрать другую модель из Hugging Face Model Hub (https://huggingface.co/models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c923c4f2e70a5acc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T15:18:34.520621Z",
     "start_time": "2024-12-08T15:18:33.339505Z"
    }
   },
   "outputs": [],
   "source": [
    "# Загрузка предобученной модели\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c782f173701c97",
   "metadata": {},
   "source": [
    "## 5. Обучение модели\n",
    "\n",
    "Используем Trainer из Hugging Face для упрощения процесса обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e6605ae077aac26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T01:44:52.459989Z",
     "start_time": "2024-12-08T15:18:47.599742Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pront\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 56129/56129 [3:27:33<00:00,  4.51it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 7.2036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 6237/6237 [07:28<00:00, 13.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 7.1449\n",
      "\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 56129/56129 [3:31:31<00:00,  4.42it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 7.1332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 6237/6237 [07:28<00:00, 13.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 7.1272\n",
      "\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 56129/56129 [3:31:42<00:00,  4.42it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 7.1056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 6237/6237 [07:27<00:00, 13.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 7.1199\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('models/model_v2\\\\tokenizer_config.json',\n",
       " 'models/model_v2\\\\special_tokens_map.json',\n",
       " 'models/model_v2\\\\vocab.json',\n",
       " 'models/model_v2\\\\merges.txt',\n",
       " 'models/model_v2\\\\added_tokens.json')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "import torch.nn as nn\n",
    "\n",
    "# Проверка наличия GPU\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Параметры обучения\n",
    "epochs = 3\n",
    "learning_rate = 5e-5\n",
    "warmup_steps = 500\n",
    "\n",
    "# Определение оптимизатора и планировщика\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "total_steps = len(train_loader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=warmup_steps,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "# Критерий потерь\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "\n",
    "# Функция обучения на одной эпохе\n",
    "def train_epoch(model, dataloader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(dataloader, desc=\"Training\"):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    return avg_loss\n",
    "\n",
    "# Функция валидации на одной эпохе\n",
    "def eval_epoch(model, dataloader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Validation\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    return avg_loss\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Цикл обучения\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scheduler, device)\n",
    "    print(f\"Training loss: {train_loss:.4f}\")\n",
    "\n",
    "    val_loss = eval_epoch(model, val_loader, device)\n",
    "\n",
    "    print(f\"Validation loss: {val_loss:.4f}\")\n",
    "\n",
    "    # Можно добавить сохранение модели после каждой эпохи\n",
    "    model.save_pretrained(f'model_epoch_{epoch + 1}')\n",
    "    tokenizer.save_pretrained(f'model_epoch_{epoch + 1}')\n",
    "\n",
    "\n",
    "# После завершения обучения сохраним модель и токенизатор для дальнейшего использования.\n",
    "model_save_path = 'models/model_v2'\n",
    "model.save_pretrained(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e00587b58cc67bc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T08:58:17.117926Z",
     "start_time": "2024-12-09T08:58:16.686514Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сгенерированный отзыв:\n",
      "и них великная и ожидание куб вкус своей есть оченьняя понравилась своему прив\n"
     ]
    }
   ],
   "source": [
    "def generate_review(category, rating, keywords, max_length=150, temperature=0.7, top_k=50, top_p=0.95):\n",
    "    prompt = f\"Категория: {category}\\nРейтинг: {rating}\\nКлючевые слова: {keywords}\\nОтзыв:\"\n",
    "    inputs = tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            inputs,\n",
    "            max_length=inputs.shape[1] + max_length,\n",
    "            temperature=temperature,\n",
    "            top_k=top_k,\n",
    "            top_p=top_p,\n",
    "            do_sample=True,\n",
    "            num_return_sequences=1,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    # Извлечение только текста отзыва\n",
    "    review = generated_text.split('Отзыв:')[-1].strip()\n",
    "    return review\n",
    "\n",
    "\n",
    "category = \"ресторан\"\n",
    "rating = 5\n",
    "keywords = \"паста\"\n",
    "\n",
    "generated_review = generate_review(category, rating, keywords, 15, 1, 100000, 1.5)\n",
    "print(\"Сгенерированный отзыв:\")\n",
    "print(generated_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d953df67d997cab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T21:39:05.655393Z",
     "start_time": "2024-12-07T21:39:05.353431Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(\"models/model_v1\")\n",
    "tokenizer.save_pretrained(\"models/model_v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0b87d42dded48d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
